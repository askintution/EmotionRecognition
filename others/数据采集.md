# 项目进度
## ck+数据集模型
在ck+数据集上，图片下采样到64*64分辨率，训练到500步，其准确率就已经达到93.%，主要原因是ck+数据集中重复数据过多，模型识别率可以很高。调研后发现ck+数据集主要是拿来当测试集，主流的训练测试集为fer2013。

```
0 accuracy= 0.21875
100 accuracy= 0.78125
200 accuracy= 0.8125
300 accuracy= 0.9375
400 accuracy= 0.9375
500 accuracy= 0.90625
end!
```

# 数据采集方案
## 现场人脸表情采集
### 采集目标
采集在不同场景下人脸7种表情，包括（开心、愤怒、惊讶、伤心、厌恶、恐惧、平静）七个类，每个类在不同的光照背景下进行。
初步计划：
每人采集七种表情视频，在自己座位上就可以。以拍照的形式，每人采集两组正脸照片（光照强度不同），三组侧脸照片（光照强度不同）
plab B
三个摄像头分别在三面采集，强光照拍一组，若光照拍一组（不同角度拍摄（录像））

## 现有数据清洗
### fer2013数据集
#### 调用API
使用face++相关API：https://www.faceplusplus.com.cn/emotion-recognition/</br>使用表情识别需要调用两个API，首先是人脸检测，返回token，然后将token传入face analyze API，一次性可以处理5个API。(免费使用)
API文档:

- Detect API  
可以检测图片中的人脸，对于检测到的每张人脸，返回各项人脸属性，包括性别、年龄、人种、情绪等。同时还会返回 face_token，您可以将 face_token 传给其他 API 以进行后续处理和分析。
- Face Analyze API  
将人脸的 face_token 传入 Face Analyze API，您可以得到许多方面的人脸属性。您可以通过调用 Detect API 得到人脸的 face_token。Face Analyze API 允许您一次性处理 5 个 face_token。

#### 脏数据归类
将脏数据作为反例类，送入网络识别。在测试时可以增加一些脏数据看效果。

## 其他人脸表情数据集
### Real-world Affective Faces (RAF) Database
http://www.whdeng.cn/RAF/model1.html</br>
Real-world Affective Faces Database (RAF-DB) is a large-scale facial expression database with around 30K great-diverse facial images downloaded from the Internet
### vam face




## 遇到问题

1. fer2013数据集尺寸太小，Face++ Api无法检测到人脸  
尝试解决方案：  
- 将fer2013数据集padding到112*112大小后进行Face++人脸检测，但仍然无法检测人脸，考虑放弃Face++API  
- 使用微软人脸检测API，可以进行部分识别，但免费次数为3w张，且其中近1/4的图片无法识别  

调用微软API将所有测试结果保存存储在txt中。

2. 搜集其他人脸识别数据集

- 北邮邓老师人脸数据集Real-world Affective Faces (RAF) Database
    - 包括29672张图像
    - 7种表情

## 后续工作

使用微软表情识别api清洗数据后，对得到数据进行分析
### 分析结果

```python
# fer2013 数据总分类
{'surprise': 4002, 'fear': 5121, 'anger': 4953, 'disgust': 547, 'happy': 8989, 'sad': 6077, 'neutral': 6198}
# 无法识别的数据及分类
{'surprise': 766, 'fear': 1308, 'anger': 1368, 'disgust': 185, 'happy': 2500, 'sad': 2188, 'neutral': 2019}
# 可以识别的数据gt分类
{'surprise': 2658, 'fear': 2754, 'anger': 2396, 'disgust': 318, 'happy': 4410, 'sad': 2387, 'neutral': 2932}
# 能够识别的图像中识别正确的数据分类
{'surprise': 1978, 'fear': 399, 'anger': 1062, 'disgust': 43, 'happy': 4113, 'sad': 692, 'neutral':2527}
# 能够识别的图像中识别错误分类的数据
# 文件夹名字为预测label，文件名为真实值
{'surprise': 613, 'fear': 112, 'anger': 482, 'disgust': 19, 'happy': 9613, 'sad': 687, 'neutral':4079, 'contempt': 88}
# 文件夹名字为真实label
{'surprise': 680, 'fear': 2355, 'anger': 1334, 'disgust': 275, 'happy': 297, 'sad': 1695, 'neutral': 405}

```

分析后发现还有7699个数据并未送入清洗。。。就很奇怪，这些数据分布为：

```python
{'sad': 1503, 'fear': 1059, 'disgust': 44, 'neutral': 1247, 'anger': 1189, 'surprise': 578, 'happy': 2079}

```
将错误文件规整到error文件夹下，可以识别的规整到normal文件夹下，在normal文件夹下分为识别正确的和识别错误这两个文件夹。

### RAF-DB数据集
aligned之后共有15,339个文件，每张图片大小为100*100像素点
分析RAF-DB数据集，其`image_rgb_mean = [146.67694408768622, 114.62698965039486, 102.31048248716525]`
其`image_rgb_std = [38.783743581401644, 34.66747586689521, 36.66802127661255]`
​                   


https://gitlab.uni-oldenburg.de/huwu6977/medienverarbeitung17.projectmood/commit/7216fb4f285a4103ae51c81255cddaa28d640f29

### AffectNet
包含Neutral, Happy, Sad, Surprise, Fear, Anger, Disgust, Contempt, None, Uncertain, Non-face共11个类

| Neutral | Happy  |  Sad  | Surprise | Fear | Anger | Disgust | Contempt | None  | Uncertain | Non-face |
| :-----: | :----: | :---: | :------: | :--: | :---: | :-----: | :------: | :---: | :-------: | :------: |
|  80276  | 146198 | 29487 |  16288   | 8191 | 28130 |  5264   |   5135   | 35322 |   13163   |  88895   |
|    0    |   1    |   2   |    3     |  4   |   5   |    6    |    7     |   8   |     9     |    10    |

None means(None of eight emotions)`, such as sleepy, bored, tired, seducing, confuse, shame, focused
Non-face means no face in image \ watermark face \ face detection failed and bounding box is not around face \face distorted
Uncertain means annotators were not certain

在进行数据分析时可以过滤掉Contempt之后的表情，用剩下7类操作。剩下使用20几w的数据集

将人脸框裁剪出来后需要将人脸关键点对应到每张人脸上，此处需要映射函数。
人脸数据中，坐标点就是人脸关键点，其将68个点的x，y的坐标表示为一个一维数组，使用时需要将x和y对应起来。
对应显示坐标点的代码为：

```python
import cv2

    file_path = 'E:/liuyuan/DataCenter\AffectNet\Manually_Annotated/Manually_Annotated/Manually_Annotated_Images' \
                '/1063/0c7ccd4a6048abf7771ff8e92f892080b28a367f9320dcfd3b112906.png'
    bbox = [32, 32, 286, 286]
    landmarks = ['114.33', '158.7', '106.05', '183.97', '104.51', '211.39', '111.4', '240.93', '118.76', '269.75',
                 '125.51', '302.85', '132.55', '333.12', '139.38', '362.09', '163.02', '374.81', '197.67', '376.97',
                 '237.41', '362.72', '278.9', '340.46', '318.35', '314.52', '346.59', '281.05', '360.07', '241.31',
                 '364.92', '199.1', '366.78', '156.23', '97.71', '125.56', '104.49', '114.75', '118.0', '115.59',
                 '132.0', '119.33', '145.88', '125.77', '175.44', '124.18', '203.88', '114.71', '235.3', '112.39',
                 '267.75', '118.4', '293.56', '134.82', '158.34', '149.15', '151.45', '170.74', '143.72', '192.7',
                 '135.9', '215.25', '129.28', '229.29', '137.61', '237.39', '149.55', '242.23', '167.22', '238.74',
                 '184.41', '233.98', '114.55', '152.87', '123.44', '143.85', '138.14', '144.86', '150.88', '152.03',
                 '137.37', '156.7', '123.62', '157.24', '211.04', '154.29', '224.73', '146.04', '242.69', '147.32',
                 '257.94', '154.41', '242.23', '158.93', '224.92', '158.11', '128.6', '275.11', '133.09', '267.78',
                 '143.8', '266.49', '154.32', '271.13', '171.77', '268.65', '199.37', '272.89', '228.09', '280.03',
                 '200.93', '303.6', '173.06', '312.76', '155.35', '312.93', '142.65', '309.95', '133.18', '299.42',
                 '133.76', '278.23', '144.1', '276.83', '155.14', '279.04', '172.34', '279.56', '220.6', '281.68',
                 '172.06', '295.85', '155.37', '294.67', '143.87', '291.55']
    emotion_label = 6
    img = cv2.imread(file_path)
    # cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
    # cv2.namedWindow("Image")
    # cv2.imshow("Image", img)
    # cv2.waitKey(0)
    for i, point in enumerate(landmarks):
        point = float(point)
        point = int(point)
        landmarks[i] = point
    landmarks = np.reshape(landmarks, (-1, 2))
    print(len(landmarks))
    for i in range(len(landmarks)):
        pos = (landmarks[i][0], landmarks[i][1])
        cv2.circle(img, pos, 2, color=(0, 255, 0))
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img, str(i / 2 + 1), pos, font, 0.2, (0, 0, 255), 1, cv2.LINE_AA)

    cv2.namedWindow("Image")
    cv2.imshow("Image", img)
    cv2.waitKey(0)
```
中间注释掉的为显示bounding-box的代码

<div align=center>    
<img src="http://p6um59a45.bkt.clouddn.com/18-11-5/92966127.jpg" width = "200" height = "200"/>
</div>

因此在数据预处理时，考虑不对图像进行人脸裁剪，直接放缩后输入网络。现在需要将图像放缩为224x224大小并调整landmark到相应位置
数据处理完整流程：

- 解压AffectNet的Image到同一个目录下
- 根据csv文件清理文件list，得到一个新的csv文件，其中存储的为file_path，landmarks， boundingbox， emotion
- 将image和landmark对应resize到224*224大小
- 输入网络

对AffectNet的数据进行清理，得到val数据为：
| Neutral | Happy  |  Sad  | Surprise | Fear | Anger | Disgust |
| :-----: | :----: | :---: | :------: | :--: | :---: | :-----: | 
|   470   | 146198 | 29487 |  16288   | 8191 | 28130 |  5264   | 
|    0    |   1    |   2   |    3     |  4   |   5   |    6    |



### 自己采集的数据集

#### face++接口
使用face++的表情识别接口来识别采集到的不同人脸表情，其识别准确率为0.40145985401459855，有点低.
分析其结果，groundTruth为：

| 表情 | surprise | anger | fear | happiness | neutral | sadness | disgust |
| :--: | :------: | :---: | :--: | :-------: | :-----: | :-----: | :-----: |
|  GT  |   174    |  228  | 348  |    453    |   184   |   255   |   139   |
| api  |   252    |   0   |  0   |    532    |   732   |   252   |   13    |

{'happy': 453, 'sick': 139, 'fear': 348, 'sad': 255, 'normal': 184, 'amazing': 174, 'angry': 228}
{'happiness': 532, 'surprise': 252, 'disgust': 13, 'neutral': 732, 'sadness': 252}

混淆矩阵：

|  GT\API   | surprise | anger | fear | happiness | neutral | sadness | disgust |
| :-------: | :------: | :---: | :--: | :-------: | :-----: | :-----: | :-----: |
| surprise  |    98    |   0   |  0   |    14     |   62    |    0    |    0    |
|   anger   |    11    |   0   |  0   |    12     |   125   |   80    |    0    |
|   fear    |    86    |   0   |  0   |    59     |   195   |    4    |    4    |
| happiness |    4     |   0   |  0   |    375    |   63    |    2    |    9    |
|  neutral  |    31    |   0   |  0   |    47     |   106   |    0    |    0    |
|  sadness  |    0     |   0   |  0   |    18     |   101   |   136   |    0    |
|  disgust  |    22    |   0   |  0   |     7     |   80    |   30    |    0    |

#### 微软接口

