# 模型调研

## DAN
DAN是用于人脸对齐的，主要会进行人脸关键点检测，网络结构类似RNN。但由于fer2013数据集没有关键点标记，因此暂时放弃DAN方面研究

## EmotionNet
可以首先使用现有的预训练模型进行人脸对齐，再进行表情识别
分析源码后发现其首先使用dlib人脸对齐。人脸识别应用通常包括四个步骤：
1. 人脸检测，定位人脸在图像中的位置，输出人脸的位置矩形框
2. 人脸形状预测， 找出眼睛眉毛鼻子嘴巴的68个定位点
3. 人脸对齐，通过投影几何变换出一张标准脸
4. 人脸识别，在对齐的人脸图像上提取128维的特征向量，根据特征向量间的距离来进行判断识别。

人脸对齐主要是一个affine transform即仿射变换，我们在detect到人脸后会得到一个矩形位置框，需要将这个矩形里面的人脸变换到150*150大小的标准人脸，英文叫做chip

因为装不上dlib，且dlib只是裁剪人脸，并没有进行人脸对齐，因此使用opencv进行人脸对齐操作


## 代码编写

### 图像预处理
归一化和白化。首先计算所有图片的三通道均值、再根据均值计算标准差。对每张图片都减去均值，用标准差归一化。
anaconda 环境配置有问题
随机调整饱和度、亮度、饱和度、水平翻转。
输入网络前将图像变为灰度图并归一化后输入网络。网络模型可变

当前任务：
 
- 调整网络参数及结构。当前效果训练45个epoch，loss为0.6625， acc为79.5.网络过拟合较严重
- 将裁剪得到的人脸图像送入face++api进行表情及关键点标注。

接下来的任务：

- 继续使用far数据集， 调整参数，优化模型，达到较好的acc值
- 结合数据集给出的bounding-box及人脸关键点训练人脸align部分的网络 

面向深度学习服务器通用规范修改
数据标注
5.1、5.6、。。。包含“海尔”的进行修改，参考规范      